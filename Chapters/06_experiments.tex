\chapter{Experiments} \label{chapt:Experiments}

In this chapter we experimentally validate the novel drift detectors we have introduced, and investigate the performance of drift detectors on a synthetic medical triage dataset. Section \ref{Experiments:details} specifies the details which of the experiments which will be run in this chapter. Section \ref{Experiments:bernoulli} describes some experiments with Bernoulli data streams which validate the approach taken by CDDM. Section \ref{Experiments:benchmark} investigates the performance of our drift detectors on a battery of benchmark data streams. Section \ref{Experiments:triage} introduces a data stream which simulates a medical referral triage environment, and investigates the performance of our drift detectors on this dataset. Section \ref{Experiments:conclusion} summarises this chapter and discusses future work.

%-------------------------------------------------------------------
% EXPERIMENT DETAILS
%-------------------------------------------------------------------

\section{Experiment Details} \label{Experiments:details}

This section provides details of the experiments which will be performed in the following sections. The experiments are implemented using a modified version of the Tornado framework \cite{tornado}. The experiments are performed on a 2.5 GHz Intel Core i7 with 16GB RAM. The operating system is macOS Mojave version 10.14.6. 

Within each experiment suite, we run all the drift detectors which are in Tornado. These are ADWIN \cite{ADWIN}, CUSUM \cite{CUSUM}, DDM \cite{DDM}, EDDM \cite{EDDM}, EWMA \cite{EWMA}, FHDDM \cite{FHDDM}, FHDDMS \cite{FHDDM}, FHDDMS$_{add}$ \cite{FHDDM}, HDDM$_A$ \cite{HDDM}, HDDM$_W$ \cite{HDDM}, MDDM$_A$ \cite{HDDM}, MDDM$_E$ \cite{MDDM}, MDDM$_G$ \cite{MDDM}, PH \cite{CUSUM}, RDDM \cite{RDDM}, and SeqDrift2 \cite{seq_drift}. CUSUM and PH are not the original procedure proposed by Page \cite{CUSUM}, but the modified versions described in \cite{gama_survey}. We compare these existing drift detectors with our novel detectors, BWAF and CDDM. We do not test BDDM due to it being $O(t^2)$ and therefore inappropriate for data streams.

This covers the most popular drift detection methods, although there are some notable omissions. All of these methods use the error-rate operationalisation of concept drift, so LFR \cite{LFR} which is a state-of-the-art detector with an alternative operationalisation would have been a sensible comparison to CDDM. Similarly, BCMC is a Bayesian approach to concept drift detection, so would have been useful to compare to BWAF. However, to our knowledge, code for these detection methods is not publicly available.

Unless otherwise stated, the experiments are run using the three most popular models implemented in Tornado. These are the perceptron \cite{perceptron}, the na\"{i}ve Bayes, and the Hoeffding tree \cite{hoeffding_trees}.

We evaluate the performance of detectors using the following metrics. A drift signal emitted by the drift detector within 250 time steps of a concept drift, is interpreted as a true positive (TP). A failure to emit a drift signal within 250 time steps of a concept drift is interpreted as a false negative (FN). A drift signal which is emitted when a concept drift has not occurred in the last 250 time steps is interpreted as a false positive (FP).  

The {\bf precision} of the detector is given by
\begin{equation}
    \text{Precision} = \frac{N_{TP}+1}{N_{TP}+N_{FP}+2}
\end{equation}
where $N_{TP}$ is the number of true positives, and similarly for $N_{FP}$ and $N_{FN}$. Note that this formula makes use of Laplace smoothing to avoid division-by-zero errors. The {\bf recall} of the detector is given by
\begin{equation}
    \text{Recall} = \frac{N_{TP}+1}{N_{TP}+1+N_{FN}+1}
\end{equation}
The {\bf F$_1$} score of the drift detector is given by
\begin{equation}
    F_1 = \frac{2}{\text{Precision}^{-1}+\text{Recall}^{-1}}.
\end{equation}
The {\bf mean delay} is the mean number of time steps between a concept drift occurring and a drift signal being emitted. Because any signals after 250 time steps are considered false positives, this is the maximum value for mean delay. {\bf Memory} is the memory footprint of the drift detector in bytes measured at the end of an experimental trial. {\bf Runtime} is the number of milliseconds between the beginning and end of the experimental trial.

The mean and standard deviation of each of these metrics is reported across all experimental trials. 

%-------------------------------------------------------------------
% BERNOULLI
%-------------------------------------------------------------------

\section{Bernoulli Experiments} \label{Experiments:bernoulli}

In this section we describe and experiment on two Bernoulli data streams. The first is intended to highlight the comparative advantage of CDDM. The second is intended to be a more ``typical" Bernoulli stream to demonstrate that the comparative advantage doesn't only exist for contrived data streams.

\subsubsection{Real and Virtual Drift}

We now present a data stream intended to illustrate how concept drift is detected using calibrated probability estimates for medical referrals triage.  This data stream embodies several kinds of drifts which may occur and for which an error-rate based drift detector will be ill-equipped to handle. In particular, it involves feature drift and noise which is unevenly distributed in feature space. These factors can result in false positives and false negatives for a error-rate based drift detector.

The data stream consists of a single Bernoulli variable $x$, and a binary label $y$. Initially, the value of $x$ is distributed as $P(x=1)=p$, and the value of $y$ is given by $y=x$. However, noise is present in the $x=1$ region of feature space, so that with probability $\epsilon$ the label will be negated. That is,
\begin{equation}
	P(y=1|x) = \begin{cases} 0 & \text{if $x=0$} \\ 1-\epsilon & \text{if $x=1$}. \end{cases}
\end{equation}
The irreducible error rate is thus $p\epsilon$. At time $\tau$, the data stream will drift in one of two ways. The first is a feature drift, in which $P(x=1)$ becomes $1-p$. If $\epsilon(2-p)>0$, then the irreducible error rate will increase, thereby triggering a false positive in an error-rate based drift detector. 

The second is a feature drift (with the same details as above) in addition to a real drift so that $x=1$, the correct label is now $y=0$ (still with a noise rate of $\epsilon$). In this case, if $1<\epsilon+p$ then the change in irreducible error rate will {\it decrease}, resulting in a false negative for a drift detector. 

We evaluated how well drift detectors can differentiate between these two scenarios by fixing the noise level at $\epsilon=0.2$, and for given $p$ values between 0 and 1, running 1000 time steps in the initial concept, and then 1000 time steps in the drifted concept. This is repeated 100 times for each value of $p$ for both the real and virtual drift conditions. The percentage of trials which result in a positive drift detection for each detector are shown in Figures \ref{fig:vdrift_plot} and \ref{fig:rdrift_plot}. We see that CDDM can reliably avoid false positives from virtual drift, unlike HDDM-A and RDDM, although this does come at the cost of lower sensitivity to true positives. 

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{vdrift_plot.pdf}
    \caption{Percentage of (false) positive drift detections for the Bernoulli data stream with virtual drift.}
    \label{fig:vdrift_plot}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{rdrift_plot.pdf}
    \caption{Percentage of (true) positive drift detection for the Bernoulli data stream with real drift.}
    \label{fig:rdrift_plot}
\end{figure}

\subsection{Setting}

Each instance consists of a Bernoulli variable, and each label is a Bernoulli variable whose rate depends on the value of the instance:
\begin{align}
  \Pr(x=i) &= \begin{cases}
    1-\gamma & \text{if }x=0 \\
    \gamma & \text{if }x=1.
    \end{cases} \\
  \Pr(y=1|x=i) &= \begin{cases}
    \alpha & \text{if }x=0 \\
    \beta & \text{if }x=1.
    \end{cases}
\end{align}
We will call $\gamma$ the instance rate, $\alpha$ the zero rate, and $\beta$ the one rate. The instance-label joint probability of the data stream may be represented graphically as in Figure \ref{fig:bernoulli}.

We are interested in two kinds of concept drift. First we have feature drift, in which the instance rate changes, but the zero and one rate remain the same.
\begin{equation}
  (\gamma,\alpha,\beta) \Rightarrow (\gamma',\alpha,\beta)
\end{equation}
Second, we have real drift concurrent with virtual drift, in which the zero rate, one rate, and instance rate change.
\begin{equation}
  (\gamma,\alpha,\beta) \Rightarrow (\gamma',\alpha',\beta')
\end{equation}
When a drift detector is triggered by real drift, this is a true positive. However, feature drift does not entail an increase in the reducible error. It follows that a model should not be retrained in the case of feature drift. If a drift detector is triggered by feature drift, this is a false positive. 

Our experiments with Bernoulli data streams will consist of 1000 time steps under the original distribution, followed by either a real drift or a feature drift, and then 1000 time steps in the new distribution. If a drift detector is triggered after a real drift, then a count of true positives is incremented. If a detector is triggered before a real drift, or after a virtual drift, then a count of false positives is incremented. If a detector is not triggered after a real drift before the 2000 time steps have completed, then a count of false negatives is incremented. We run 2000 iterations of each data stream. The base learner we use is a na\"{i}ve Bayes. Na\"{i}ve Bayes' are known to be poorly calibrated \cite{calibrating}, so are typically a poor choice to use with CDDM. However, this issue arises due to unrealistic independence assumptions which are not invoked in a one-dimensional instance case such as this.

\subsection{Bernoulli-Hard}

To clearly illustrate the comparative advantage of CDDM in data streams with feature drift, we present a data stream called {\bf Bernoulli-hard}. In this data stream, we have one instance which is hard to predict, and one instance which is easy to predict. Specifically, an instance value of zero has zero noise, and an instance value of one has a noise value of 0.2. The instance rate is uniformly sampled.
\begin{align}
  \alpha &= 0 \\
  \beta &= 0.2 \\
  \gamma &\sim U[0,1]
\end{align}
When virtual drift occurs, the instance rate is reversed. When real drift occurs the one rate is reversed.
\begin{align}
  \alpha' &= 0 \\
  \beta &= 0.8 \\
  \gamma' &= 1 - \gamma
\end{align}
If the initial instance rate is less than 0.5, then after virtual drift we will see an increase in the error rate of the model due to an increase in the rate of ``hard problems". This can lead to false positives for drift detectors which use the error-rate operationalisation (henceforth ``error-rate detectors"). Conversely, when the instance rate is greater than 0.5, when real drift occurs we will see a decrease in the rate of ``hard problems", which will decrease the error rate. This may hide the increase in the error rate due to the real drift itself, and can lead to false negatives. These two scenarios are illustrated in Figure \ref{fig:bernoulli_hard}.

More specifically, the change in error rate due to feature drift will be positive when
\begin{align}
  0 &< \Delta E \\
  &< (1-\gamma)\beta - \gamma \beta \\
  &< \beta-2\gamma\beta \\
  \gamma &< 0.5.
\end{align}
Thus, any instance rate greater than 0.5 may trigger false positives in error-rate detectors. The change in error rate due to real drift is positive when
\begin{align}
  0 &< \Delta E \\
  &< (1-\gamma)(1-\beta) - \gamma\beta \\
  &< 1 - \gamma - \beta \\
  \gamma &< 0.8.
\end{align}
Thus false negatives may occur when the instance rate is above 0.8.

The results of the trials on this data stream are given in Table \ref{tab:bernoulli_hard}. We also plot the true positive, false positive and false negative rates against the instance rate to illustrate the results derived in the previous paragraph. 

\begin{figure}
    \centering
    % \includegraphics[width=0.5\textwidth]{images/bernoulli.jpg}
    \begin{tikzpicture}[scale=6]
        %--- Arguments ----
        \def \g {0.45} % gamma
        \def \a {0.6} % alpha
        \def \b {0.3} % beta
        \def \zeroColor {Dandelion} % colour of y=0 boxes
        \def \oneColor {Green} % colour of y=1 boxes
        \def \textsep {0.05}
        %--- Rectangles ---
        \draw [fill=\zeroColor] (0,0) rectangle (\g,1-\a);
        \draw [fill=\oneColor] (0,1-\a) rectangle (\g,1);
        \draw [fill=\zeroColor] (\g,0) rectangle (1,1-\b);
        \draw [fill=\oneColor] (\g,1-\b) rectangle (1,1);
        %--- Lines ---
        % alpha
        \draw [<->] (-\textsep, 0) -- (-\textsep, 1-\a);
        \draw [<->] (-\textsep, 1-\a) -- (-\textsep, 1);
        % gamma
        \draw [<->] (0, -\textsep) -- (\g, -\textsep);
        \draw [<->] (\g, -\textsep) -- (1,-\textsep);
        % beta
        \draw [<->] (1+\textsep, 0) -- (1+\textsep, 1-\b);
        \draw [<->] (1+\textsep, 1-\b) -- (1+\textsep, 1);
        %--- Outer labels ---
        % alpha
        \node [left] at (-\textsep, 0.5-\a/2) {$1-\alpha$};
        \node [left] at (-\textsep, 1-\a/2) {$\alpha$};
        % gamma
        \node [below] at (\g/2,-\textsep) {$\gamma$};
        \node [below] at (0.5+\g/2,-\textsep) {$1-\gamma$};
        % beta
        \node [right] at (1+\textsep, 0.5-\b/2) {$1-\beta$};
        \node [right] at (1+\textsep, 1-\b/2) {$\beta$};
        %--- Inner labels ----
        \node [scale=0.75] at (\g/2,0.5-\a/2) {$P(x=0,y=0)$};
        \node [scale=0.75] at (\g/2,1-\a/2) {$P(x=0,y=1)$};
        \node [scale=0.75] at (0.5+\g/2,0.5-\b/2) {$P(x=1,y=0)$};
        \node [scale=0.75] at (0.5+\g/2,1-\b/2) {$P(x=1,y=1)$};
    \end{tikzpicture}
    \caption{Distribution of the Bernoulli data stream.}
    \label{fig:bernoulli}
\end{figure}

\begin{figure}
    \centering
    % \includegraphics[width=0.5\textwidth]{images/bernoulli_hard.jpg}
    \begin{tikzpicture}[scale=4]
        % --- DEFINITIONS ---
        \def \xSep {2}
        \def \ySep {1.5}
        \def \arrowSep {0.2}
        \def \textSep {0.2}
        \def \gZero {0.25}
        \def \gOne {0.75}
        \def \bZero {0.7}
        \def \bOne {0.3}
        \def \zeroColor {Dandelion} % colour of y=0 boxes
        \def \oneColor {Green} % colour of y=1 boxes
        % \def \zeroColor {Dandelion} % colour of y=0 boxes
        % \def \oneColor {Green} % colour of y=1 boxes
        \newcommand{\bernSqr}[4]{
            % draw a Bernoulli square
            % args:
            %  x value of bottom left
            %  y value of bottom left
            %  gamma
            %  beta
            \draw [fill=\oneColor] (#1,#2) rectangle (#1+#3,#2+1);
            \draw [fill=\zeroColor] (#1+#3,#2) rectangle (#1+1,#2+1-#4);
            \draw [fill=\oneColor] (#1+#3,#2+1-#4) rectangle (#1+1,#2+1);
        }
        % --- SQUARES ---
        \bernSqr{0}{0}{\gZero}{\bZero}
        \bernSqr{\xSep}{0}{\gOne}{\bOne}
        \bernSqr{0}{\ySep}{\gZero}{\bZero}
        \bernSqr{\xSep}{\ySep}{\gOne}{\bZero}
        % --- ARROWS ---
        \draw [ultra thick, ->] (1+\arrowSep,0.5) -- (\xSep-\arrowSep,0.5);
        \draw [ultra thick, ->] (1+\arrowSep,\ySep+0.5) -- (\xSep-\arrowSep,\ySep+0.5);
        % --- TEXT ---
        \node at (0.5+\xSep/2,-\textSep) {Real drift};
        \node at (0.5+\xSep/2,\ySep-\textSep) {Feature drift};
    \end{tikzpicture}
    \caption{Distributional changes in the Bernoulli-hard data stream.}
    \label{fig:bernoulli_hard}
\end{figure}

\subsection{Bernoulli-Typical}

One may object that the previous data stream was tailor-made to showcase CDDM. We demonstrate that this is not the case with another data stream called {\bf Bernoulli-typical} which gives a much more generic picture of false positive and false negative responses from error-rate detectors. In this dataset we do not hand-pick any of the rates. Instead we sample each of them uniformly.
\begin{align}
  \alpha &\sim U[0, 0.5] \\
  \beta &\sim U[0, 0.5] \\
  \gamma &\sim U[0, 1]
\end{align}
The only constraint we place is that after real drift the zero and one rates should increase. This is because most drift detectors deliberately do not detect decreases in the error rate in case it is a result of learning. Allowing decreases in the zero and one rates would thus give CDDM an unfair advantage.
\begin{align}
  \alpha' &\sim U[\alpha, 1] \\
  \beta' &\sim U[\beta, 1] \\
  \gamma' &\sim U[0, 1]
\end{align}

The results of the trials on this data stream are given in Table \ref{tab:bernoulli_hard}.

%-------------------------------------------------------------------
% BENCHMARK DATASETS
%-------------------------------------------------------------------

\section{Benchmark Datasets} \label{Experiments:benchmark}

In this section we evaluate the concept drift detection methods we have introduced on a battery of benchmark datasets. The Tornado framework provides implementations of the following synthetic data streams:
\begin{itemize}
    \item {\bf CIRCLES} Each instance consists of two attributes $x_1,x_2\sim U[0,1]$. Each concept consists of three values, $r,x_{circ},y_{circ}\in[0,1]$, representing the radius of a circle, and $x$ and $y$ coordinates of the center of a circle. And instance is given a positive label if it falls within the circle, otherwise it is given a negative label. Sampling is done such that an equal number of positive and negative instances occur. The concept parameters cycle through the values of $[0.15, 0.2, 0.5]$, $[0.2, 0.4, 0.5]$, $[0.25, 0.6, 0.5]$ and $[0.3, 0.8, 0.5]$.
    \item {\bf LED} Each concept in the LED task is a digit displayed on a 7-bit LED interface. There are 10 labels (the digits $0,1,2,\dots,9$) and 7 binary features (each of the display bits).  For example, the label corresponding to the instance [1, 1, 1, 1, 1, 1, 0] is $0$. In addition to the concept bits, there are also $n$ irrelevant and random-valued binary attributes. The position of the irrelevant attributes changes with each concept, so the model must learn anew which attributes are decision-relevant. 
    \item {\bf MIXED} Each instance is a mix of two binary attributes $w,v\in\{0,1\}$, and two real-valued attributes $x_1,x_2\sim U[0,1]$. Labels are assigned according to $y=\mathrm{1}[v \wedge w \wedge  y < 0.5 + 0.3 \sin(3\pi x)]$. After each context change the classification is reversed.
    \item {\bf SEA} Each instance consists of three attributes $x_1,x_2,x_3\sim U[0,10]$. Each concept consists of a threshold $\theta$, such that $y=\mathrm{1}[x_1+x_2+x_3 > \theta]$. That is, if the binary label denotes whether the sum of the attributes exceeds the threshold. Thresholds cycle between the values $[8, 9, 7, 9.5]$.
    \item {\bf SINE1} Each instance consists of two attributes $x_1,x_2\sim U[0,1]$. Binary labels are given by $y = \mathrm{1}[x_1>sin(x_2)]$. When concept drift occurs, the labels are reversed.
    \item {\bf SINE2} As with SINE1, the attributes are $x_1,x_2\sim U[0,1]$. Binary labels are given by $y = \mathrm{1}[x_1>0.5+0.3\sin(3\pi x_2)]$. When concept drift occurs, the labels are reversed.
    \item {\bf STAGGER} Instances consist of categorical attributes $size\in [small, medium, large]$, $color\in [red, green]$, $shape\in [circular, non-circular]$. Each concepts is a first order logic expression. Specifically, the following concepts are cycled: $y=\mathrm{1}[size=small \wedge color=red]$, $y=\mathrm{1}[color=green \vee shape=circular]$, and $y=\mathrm{1}[size=medium \vee size=large]$.
\end{itemize}
These data streams provide constitute the most popular benchmarks used in the concept drift detection literature. Each of these data streams has the following parameters:
\begin{itemize}
    \item {\bf Concept Length} The number of instances between concept drifts. If this number is small then the data stream is {\it volatile}, if this number is small then the data stream is {\it stable}.
    \item {\bf Transition Length} The number of instances over which a concept drift occurs. If the transition length is $n$, and there have been $i$ instances since the concept drift, then the probability that the new concept is used is $P(new-concept)=i/n$, otherwise the previous concept is used. If the transition length is low then the drift is {\it abrupt}. Otherwise the stream is {\it gradual}.
    \item {\bf Noise Rate} The rate at which any given label will be replaced with a different label. For binary labels, the label is simply inverted. Otherwise, a different label is chosen at random. If this quantity is high, then the data stream is {\it noisy}.
\end{itemize}
We are interested in how drift detector performance varies with noise and transition length. We therefore run experiments using each of the variations of the above datasets
\begin{itemize}
    \item {\bf High Noise} Noise rate is set to 0.4, transition length is set to 50 and concept length is set to 1000.
    \item {\bf Low Noise} Noise rate is set to 0.02, transition length is set to 50 and concept length is set to 1000.
    \item {\bf Gradual Drift} Transition length is set to 250, noise rate is set to 0.1, and concept length is set to 1000.
    \item {\bf Abrupt Drift} Transition length is set to 0, noise rate is set to 0.1, and concept length is set to 1000.
    \item {\bf Long concepts} Transition length is set to 50, noise rate is set to 0.1, and concept length is set to 25000.
    \item {\bf Short concepts} Transition length is set to 50, noise rate is set to 0.1, and concept length is set to 250.
\end{itemize}
We run each datastream with two base learners. Na\"{i}ve Bayes and Hoeffding trees \cite{hoeffding_trees} are two of the most popular, so we use these.  

We run two iterations of each of the 7 data streams, for each of the four variations, with both of the base learners. The results are given in Table \ref{tab:benchmarks} and visualised in Figure \ref{fig:benchmarks}. 

\begin{sidewaystable}
    \centering
    \caption{Results of benchmark datasets.}
    \input{tables/benchmark.tex}
    \label{tab:benchmarks}
\end{sidewaystable}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/cd_diagrams/benchmark.pdf}
    \caption{CD diagram of benchmark datasets.}
    \label{fig:benchmarks}
\end{figure}

We see that BWAF performs well on benchmark datasets. It achieves the fifth highest precision (significantly less than the best detector at $p<0.05$), the seventh best recall (not significantly less than the best detector at $p<0.05$), the fourth best F$_1$ score (not significantly less than the best detector at $p<0.05$), the best mean delay (although not significantly greater than the second best at $p<0.05$), the fifth best memory consumption (not significantly worse than the best detector at $p<0.05$), but the second worst runtime.

By contrast, the performance of CDDM is poor. Because the instances in these data streams are high dimensional, the learners are uncalibrated, triggering a high rate of false positives. On recall and memory, CDDM is ranked in the middle the detectors. On all other metrics it is in the lower half of detectors. This affirms the statement in Section \ref{CDDM:conclusion} that CDDM must be extended with online calibration for practical usage.

%-------------------------------------------------------------------
% SYNTHETIC MEDICAL
%-------------------------------------------------------------------

\section{Triage Simulation} \label{Experiments:triage}

In this section we evaluate our novel concept drift detectors in the motivating example domain of GP referrals triage. Due to a lack of real triage data annotated by concept drift, we instead use a synthetic data stream with concept drift deliberately introduced.

We base our synthetic data stream on the MIMIC-III dataset - a publicly available repository of free-text electronic health records \cite{mimic}. There are several types of documents within the dataset, so we limit our usage to `radiology' documents, which have the advantage of having structured headers. We preprocess the 522,279 radiology documents by converting the text into bag-of-words format. To keep the instance dimensionality reasonable, we eliminate tokens which occur in fewer than 40\% or more than 60\% of documents, resulting in 59,652 dimensional features. We shuffle the order of the documents to make sure the only concept drifts which occurs in the data stream have been deliberately engineered.

To simulate a triage rule, we randomly label 30 referral documents with priority labels 1 to 4. We then train a decision tree on these instance-label pairs. We repeat this several times to obtain a set of ``triage concepts". Concept drift is simulated by labelling the instances prior to the drift point using one triage concept, and then labelling the instances after the drift with another, randomly selected concept. In each instantiation of the data stream a single concept drift occurs halfway through the stream.

We run two iterations of the medical triage data stream under each of the variations described in Section \ref{Experiments:benchmark}, namely high noise, low noise, gradual drift, abrupt drift, long concepts, short concepts. The results are given in Table \ref{tab:triage} and visualised in Figure \ref{fig:triage}. 

\begin{sidewaystable}
    \centering
    \caption{Results of synthetic triage data streams.}
    \input{tables/mimic.tex}
    \label{tab:triage}
\end{sidewaystable}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/cd_diagrams/mimic.pdf}
    \caption{CD diagram of synthetic triage data streams.}
    \label{fig:triage}
\end{figure}

Similar to Section \ref{Experiments:benchmark}, we see competitive performance from BWAF. It achieves the second highest precision, recall, and F$_1$ score, as well as the third best mean delay (none of which is significantly worse than the best detector at $p<0.05$). The memory consumption is sixth best (not significantly less than the best detector at $p<0.05$), although the runtime is fifth worst.

As in Section \ref{Experiments:benchmark}, the performance of CDDM is poor. CDDM achieved the worst precision and F$_1$ of all the detectors, although it achieved the sixth best recall, the best mean delay, the second best memory consumption, and the third lowest runtime. As before, this poor performance can be attributed to the models being miscalibrated, a problem which is especially acute given the high dimensionality of the data. 

%-------------------------------------------------------------------
% CONCLUSION
%-------------------------------------------------------------------

\section{Conclusion} \label{Experiments:conclusion}

In this chapter we experimentally validated our novel drift, and investigated the performance of drift detectors on a synthetic medical triage dataset. We have seen that BWAF is a competitive drift detector on a battery of benchmark data streams, and a synthetic GP referrals triage data stream. It consistently achieved one of the best precision, recall, F$_1$, detection delays scores. BWAF's memory usage reasonable, consistently within the top quartile, although its runtime was generally not competitive. CDDM did not perform competitively in these experiments. We attribute this to the models being uncalibrated, thus affirming the claim made in Section \ref{CDDM:conclusion} that CDDM should be combined with online calibration for practical usage.