\chapter{Conclusion} \label{chapt:Conclusion}

In this chapter we summarise our work and promising future work. Section \ref{conclusion:achievements} highlights major achievements of this thesis. Section \ref{conclusions:limitations} identifies the main limitations of our work. Section \ref{conclusions:future_word} discusses the most promising future work.

%-------------------------------------------------------------------
% ACHIEVEMENTS
%-------------------------------------------------------------------

\section{Achievements} \label{conclusion:achievements}

The following list highlights the major achievements of our research:

\noindent{\bf Chapter \ref{chapt:MDD}}
\begin{itemize}
  \item We introduced multiple drift detector (MDD), a framework  for monitoring for several types of concept drift, specifically real drift, label drift, and feature drift.
  \item This allows users to receive early warnings that a model is no longer fit for purpose due to changes in the instance distribution, so that the model can be recalled if necessary.   
  \item MDD is flexible and can be implemented using any existing drift detection method.
  \item We also introduced a graphical interface for visualising the evolution of the data stream.
%   introduced a framework for providing early warnings that a model requires retraining or recall, the multiple drift detector (MDD). MDD monitors the instance distribution, the label distribution, {\it and} the instance-label joint distribution for signs of drift. MDD is constructed out of an ensemble of existing drift detectors, and has significant flexibility in its implementation. We also present a graphical interface for visualising the history of the status of MDD.
\end{itemize}
{\bf Chapter \ref{chapt:CDDM}}
\begin{itemize}
  \item We introduced calibrated drift detection method (CDDM), a drift detector which only detects reducible, and not irreducible, performance degradation. 
  \item CDDM is thus able to avoid false positives due to feature drift which do not change the decision boundary. In these cases, retraining the model is at best pointless and at worst detrimental due to reducing the size of the training data.
  \item We demonstrated the value of CDDM by achieving the highest F$_1$ score on a Bernoulli data stream with feature drift and variation in prediction difficulty.
\end{itemize}
{\bf Chapter \ref{chapt:BDD}}
\begin{itemize}
  \item We introduced Bayesian drift detection method (BDDM), a method for exactly calculating posterior probabilities of drift timing and performance degradation. 
  \item This allows user to make more rational decisions about model retraining, based on expected utility. 
  \item BDDM is able to accommodate uneven time series, by factoring the spaces between instances into prior values.
  \item We also introduce beta with adaptive forgetfulness (BWAF), an efficient heuristic approximation of BDDM. BWAF requires only four registers of memory, and has $O(1)$ computational complexity. It also does not require parameter selection. 
  \item BWAF was shown to be competitive on standard benchmarks, achieving the second highest F$_1$ score. It was also competitive on the synthetic triage data stream, again achieving the second highest F$_1$ score.
%   \item We introduced a drift detection method which calculates exact posterior probabilities of concept drift having occurred at each time step, Bayesian drift detection method (BDDM). It also calculates posterior distributions over the values of performance metrics both before and after the occurrence concept drift.
%   \item We also introduced beta with adaptive forgetfulness (BWAF), an efficient heuristic-based drift detection method inspired by BDDM. BWAF computes posterior probabilities of drift having occurred, although unlike BDDM, the posteriors for past time steps are not updated in light of new evidence. It is, however, very space and time efficient. It also does not require parameter tuning.
\end{itemize}

%-------------------------------------------------------------------
% LIMITATIONS
%-------------------------------------------------------------------

\section{Limitations} \label{conclusions:limitations}

We identify the following major limitations of this work.

\subsection{Multiple Drift Detector}

The purpose of this system was to provide early warnings of feature drift when label values are delayed compared to feature values. However, there are limitations to the types of feature drifts which can be detected. 

By representing free-text features as bags of words, all information about the arrangement of tokens is lost, and so only changes at the token-frequency level are detectable. MDD also assumes independence between features. Thus changes in the correlation between features are undetectable by MDD.

\subsection{Calibrated Drift Detection Method}

In Chapter \ref{chapt:CDDM}, we identified two limitations of CDDM. The first was that it cannot detect ``small" deviations from miscalibration. The minimum detectable deviation depends on the window size and the detection threshold, as specified in Equation \ref{eq:window_size}. 

The second limitation is that CDDM requires its model to be calibrated. Most machine learning methods require post-processing of probabilistic predictions to become calibrated \cite{calibrating}, and these can require large amounts of training data to achieve \cite{beyond_sigmoids} and are not necessarily robust against dataset drift \cite{dataset_drift}. CDDM will therefore not be practical until progress has been made on the problem of online calibration. 

\subsection{Bayesian Concept Drift Detection}

The main limitation of BDDM is that it scales poorly, being $O(t^2)$ in time and $O(t)$ in space. It is thus impractical for high-volume data streams. 

The main limitation of BWAF is that the heuristics it uses to approximate BDDM are not well motivated theoretically. It is not known if they introduce biases or inefficiencies.  

%-------------------------------------------------------------------
% FUTURE WORK
%-------------------------------------------------------------------

\section{Future Work} \label{conclusions:future_word}

We suggest the follow as promising directions for future work.

\subsection{User Testing}

In Chapter \ref{chapt:Introduction}, we motivated our work as bridging a gap between academic research on concept drift and real data science applications. We used GP referrals triage as a motivating example for this discussion. However, we have not yet shown that our algorithms actually help users in real applications.

It would therefore be valuable to evaluate our algorithms and frameworks with user tests and case studies. Are users able to effectively interpret the early warnings from MDD? How often do the kinds of false positives and false negatives that CDDM prevents come up in real data streams? We have argued that the probability distributions provided by BDDM and BWAF will help experts make expected utility calculations, but are real application domains to well-specified enough for this to be possible?

\subsection{Online Calibration}

CDDM assumes that models are calibrated, which is not true of most learning algorithms. Calibration can be achieved off-line via techniques such as calibration maps \cite{beyond_sigmoids}\cite{calibrating}, but these can require large samples of data \cite{beyond_sigmoids}. 

It would therefore be beneficial to investigate avenues by which CDDM could be applied to models which are not automatically calibrated. One way to achieve this is via calibrating learners online, an area which has not been well studied. 

\subsection{Bayesian Drift Detection}

BWAF has shown promise as a drift detector, achieving the second highest F$_1$ score of the detectors tested in the benchmark data streams. It would be worthwhile conducting further theoretical and experimental investigations into BWAF's performance. 

Specifically, it would be worth investigating whether it is possible to prove theoretical guarantees on the false positive and false negative rate of BWAF. Additionally, experimentally determining under what circumstances BWAF tends to perform well or perform poorly. Can the computational efficiency of BWAF be significantly improved? Are there other heuristic approaches to Bayesian drift detection which achieve even better performance than BWAF?